# üß† Neural Interface // Local AI

> Uma interface de Intelig√™ncia Artificial rodando 100% localmente, focada em privacidade, sem filtros corporativos e com persist√™ncia de mem√≥ria.

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Streamlit](https://img.shields.io/badge/Frontend-Streamlit-red)
![Ollama](https://img.shields.io/badge/Backend-Ollama-black)
![Status](https://img.shields.io/badge/Status-Em_Desenvolvimento-yellow)

## üìã Sobre o Projeto

Este projeto consiste em uma implementa√ß√£o Full-Stack de um assistente de IA pessoal. Diferente de solu√ß√µes comerciais (ChatGPT, Gemini), todo o processamento ocorre no pr√≥prio hardware do usu√°rio ou em um servidor dom√©stico, garantindo que nenhum dado deixe a rede local.

### Principais Funcionalidades
- **Totalmente Offline:** Utiliza a API local do [Ollama](https://ollama.com/) para infer√™ncia.
- **Sem Censura:** Projetado para rodar modelos "uncensored" (como Dolphin-Llama3), removendo barreiras de alinhamento corporativo.
- **Mem√≥ria Persistente:** Sistema de logs em JSON que permite √† IA "lembrar" de conversas passadas mesmo ap√≥s reinicializa√ß√£o.
- **Interface Cyberpunk:** Frontend desenvolvido em Streamlit com tema dark mode customizado e responsivo.
- **Arquitetura Flex√≠vel:** Pode rodar em GPUs High-End (RTX 4070+) ou ser adaptado para CPUs antigas (via modelos quantizados como Qwen/Phi-3).

## üõ†Ô∏è Tech Stack

* **Linguagem:** Python
* **Interface:** Streamlit
* **LLM Engine:** Ollama
* **Modelos Testados:**
    * `dolphin-llama3` (Para Hardware com GPU dedicada)
    * `qwen2.5:0.5b` (Para Servidores CPU/Low-end)

## üöÄ Como Rodar

### Pr√©-requisitos
1.  **Linux** (Ubuntu/Debian/Fedora)
2.  **Python 3.10+**
3.  **Ollama** instalado e rodando (`curl -fsSL https://ollama.com/install.sh | sh`)

### Instala√ß√£o

```bash
# 1. Clone o reposit√≥rio
git clone [https://github.com/SEU_USUARIO/minha-ia-local.git](https://github.com/SEU_USUARIO/minha-ia-local.git)
cd minha-ia-local

# 2. Crie e ative o ambiente virtual
python3 -m venv venv
source venv/bin/activate

# 3. Instale as depend√™ncias
pip install -r requirements.txt
